{"0": {"explanation": "Explanation: The neuron is looking for the word \"Everybody\" as a token", "answers": ["Activating tokens: Everybody (10)", "Activating tokens: Everybody (10)", "Activating tokens: Everybody (10)", "Activating tokens: Everybody (10)", "Activating tokens: Everybody (10)", "Activating tokens: Everybody (10)", "Activating tokens: Everybody (10)", "Activating tokens: Everybody (10)", "Activating tokens: Everybody (10)", "Activating tokens: Everybody (10)"], "correct": [[[" Everybody"], [8]], [[" Everybody"], [8]], [["Everybody"], [6]], [["Everybody"], [6]], [["Everybody"], [6]], [["Everybody", "Everybody"], [6, 6]], [[" Everybody"], [8]], [[" Everybody"], [7]], [[" Everybody"], [8]], [[" Everybody"], [8]]]}, "3": {"explanation": "Explanation: The neuron is looking for references to \"watch\" or \"watching\", either as a noun (a timepiece) or a verb (to observe or monitor)", "answers": ["Activating tokens: watching (8)", "Activating tokens: Watch (8)", "Activating tokens: watching (8)", "Activating tokens: watch (8)", "Activating tokens: watches (10), watching (0)", "Activating tokens: watch (8)", "Activating tokens: watchmaker (8)", "Activating tokens: watchful (8)", "Activating tokens: Watch (8)", "Activating tokens: watching (8)"], "correct": [[[" watching"], [1]], [[" Watch"], [1]], [["watching"], [2]], [[" watch"], [1]], [[" watch"], [1]], [[" watch"], [1]], [[" watch"], [1]], [[" watch"], [1]], [[" Watch"], [3]], [[" watching"], [1]]]}, "4": {"explanation": "Explanation: The neuron is looking for proper nouns, specifically names of people (e", "answers": ["Activating tokens: Skinner (8)", "Activating tokens: John Seymour (8)", "Activating tokens: Skinner (8), Odysseus (8)", "No activating tokens", "Activating tokens: Walter Johnson (8), Manning Marable (8), Seymour Melman (8)", "Activating tokens: Mitchell (8), Wagner (8), Wakefield (8), Kassolke (8), Golding (8), Vagg (8), Wakefield (8), Smith (8), Rose (8), Jackman (", "Activating tokens: Wagner (8), Afrojack (8), PSY (8)", "Activating tokens: Huntzinger (8), Hutchins (8), Gierke (8), Sutherland (8)", "No activating tokens", "Activating tokens: Barbara Hoatson (10)"], "correct": [[[" Skinner"], [8]], [[" Seymour"], [6]], [[" Skinner"], [8]], [[" disposal"], [5]], [[" Seymour"], [6]], [[" Wagner"], [7]], [[" Wagner"], [7]], [[" Sutherland"], [10]], [[" disposal"], [5]], [[" Sutherland"], [10]]]}, "5": {"explanation": "Explanation: The neuron is looking for words related to \"wipers\" or \"fiddles\", possibly with a focus on the suffix \"-ipers\" or \"-iddle\"", "answers": ["Activating tokens: fiddle (10), fiddles (0), fiddle (10)", "Activating tokens: Riddle (8)", "Activating tokens: Biddle (8)", "Activating tokens: fiddle (8), fiddle (8)", "Activating tokens: pipers (8)", "Activating tokens: fiddle (8)", "Activating tokens: riddle (8)", "Activating tokens: wipers (0), but antiperspir (8)", "Activating tokens: Fiddle (10)", "No activating tokens"], "correct": [[["iddle", "iddle"], [6, 6]], [["iddle"], [5]], [["iddle"], [5]], [["iddle", "iddle"], [5, 5]], [["ipers"], [7]], [["iddle"], [5]], [["iddle"], [5]], [["ipers"], [8]], [["iddle"], [6]], [["ipers", "ipers"], [6, 6]]]}, "6": {"explanation": "Explanation: The neuron is looking for terms related to scientific or medical concepts, such as laboratory techniques, diseases, or biological processes", "answers": ["No activating tokens", "Activating tokens: maternity (8)", "Activating tokens: acute lymphoblastic leukemia (10), bone marrow (8)", "Activating tokens: fluorescent (8), abattoir (4)", "Activating tokens: leukemia (8), worms (4), morbidity (9), mortality (9)", "No activating tokens", "Activating tokens: leukemia (8), multiple myeloma (8), priapism (10)", "Activating tokens: fluorescent (8)", "Activating tokens: prenatal (8), Cesarian (9)", "No activating tokens"], "correct": [[[" lashes"], [5]], [[" maternity"], [5]], [[" leukemia"], [5]], [[" fluorescent"], [6]], [[" leukemia"], [5]], [[" fluorescent"], [6]], [[" leukemia"], [5]], [[" fluorescent"], [6]], [[" maternity"], [5]], [[" lashes"], [5]]]}, "7": {"explanation": "Explanation: The neuron is looking for the prefix \"Mu\" in a word, regardless of its meaning or context", "answers": ["Activating tokens: Muve (10)", "Activating tokens: Muenkler (8)", "Activating tokens: mud (5), Mujib (8)", "Activating tokens: \u00d3 Muilleoir (8)", "Activating tokens: Mu (10), Mu (10), Aakhuamu (8), Aakhuamu (8)", "Activating tokens: Mu (10), Mu (10)", "Activating tokens: Muir (8)", "Activating tokens: Music (8), Mu (10)", "Activating tokens: Muzaffarn (10)", "Activating tokens: Muir (8)"], "correct": [[[" Mu"], [10]], [[" Mu"], [10]], [[" Mu"], [10]], [[" Mu"], [10]], [[" Mu"], [10]], [[" Mu"], [10]], [[" Mu"], [10]], [[" Mu"], [10]], [[" Mu"], [10]], [[" Mu"], [10]]]}, "9": {"explanation": "Explanation: The neuron is looking for words related to formal proceedings or official discussions, such as \"hearings\", or expressions of personal opinions or emotions, like \"liking\" or \"said\"", "answers": ["Activating tokens: said (0), liking (8)", "Activating tokens: said (8)", "Activating tokens: said (2)", "Activating tokens: said (0), but \"complaint\" is related to formal proceedings, so activation value for \"complaint\" is 8", "Activating tokens: said (0)", "Activating tokens: said (0), but \"Assess\" could be related to formal proceedings, so Assess (2)", "Activating tokens: said (0), liking (8)", "Activating tokens: hearings (10), said (8)", "Activating tokens: said (0, not present in this document), liking (8)", "Activating tokens: said (0), hearings (8)"], "correct": [[[" liking"], [3]], [[" Heard"], [5]], [[" Heard"], [4]], [[" hearing"], [3]], [[" hearing", " hearing", " hearing", " hearing"], [2, 4, 3, 3]], [[" hearing"], [3]], [[" liking"], [3]], [[" hearings", " hearings", " hearings"], [4, 4, 4]], [[" liking"], [3]], [[" hearings"], [3]]]}, "10": {"explanation": "Explanation: The neuron is looking for words related to helping or supporting actions", "answers": ["Activating tokens: member (2), associate (1)", "Activating tokens: help (8), contribute (7), assist (not present, but \"assistants\" is present with a value of 6)", "Activating tokens: teaching (8), learning (8), researching (8), experimenting (8), contribute (9)", "Activating tokens: assistants (8)", "Activating tokens: helps (8), supplementation (7)", "Activating tokens: fix (8), help (not present but related concept \"Band-Aid\" is present with activation value 7)", "Activating tokens: supplementation (8), supporting (0)", "Activating tokens: enable (8), assist (9)", "Activating tokens: supporting (5)", "Activating tokens: called (4)"], "correct": [[[" assist"], [3]], [[" assistants"], [4]], [[" assistants"], [4]], [[" assistants"], [4]], [[" supplementation"], [4]], [["Aid", " aid"], [4, 0]], [[" supplementation"], [4]], [[" assist"], [3]], [[" supplementation"], [4]], [[" assistants"], [4]]]}, "11": {"explanation": "Explanation: The neuron is looking for the word \"body\"", "answers": ["Activating tokens: body (8)", "No activating tokens", "Activating tokens: body (8)", "Activating tokens: body (8)", "Activating tokens: body (2)", "Activating tokens: body (2), full-body (1)", "Activating tokens: body (8)", "Activating tokens: body (10)", "No activating tokens", "Activating tokens: valvebody (8), body (10)"], "correct": [[["body"], [5]], [["body"], [5]], [["body"], [5]], [["body"], [5]], [["body", "body"], [5, 6]], [["body"], [5]], [["body"], [5]], [["body"], [5]], [["body"], [5]], [["body"], [5]]]}, "12": {"explanation": "Explanation: The neuron is looking for numerical values, specifically three-digit numbers in the range of 400-490", "answers": ["Activating tokens: 470 (8), 480 (8), 490 (10)", "Activating tokens: 480 (8)", "Activating tokens: 480 (8)", "No activating tokens", "Activating tokens: 480 (8)", "Activating tokens: 402 (8), 480 (9)", "Activating tokens: 470 (8), 480 (9), 482 (7), 494 (10)", "Activating tokens: 480 (10)", "Activating tokens: 480 (8)", "Activating tokens: 480 (8)"], "correct": [[["470", "470", "480"], [4, 4, 7]], [["480"], [7]], [[" 480"], [5]], [["485"], [4]], [[" 480"], [5]], [["480"], [7]], [["470", "480", "482"], [4, 7, 2]], [[" 480"], [5]], [[" 480"], [5]], [[" 480"], [5]]]}, "13": {"explanation": "Explanation: The neuron is looking for ordinal numbers (first, second, third, fourth, etc", "answers": ["No activating tokens", "Activating tokens: third (8)", "Activating tokens: third (8)", "No activating tokens", "Activating tokens: fourth (8), third (2), seventh (5)", "No activating tokens", "Activating tokens: first (0), second (0), third (0), fourth (0)", "Activating tokens: third (8)", "Activating tokens: third (8)", "Activating tokens: first (8), second (8), third (8)"], "correct": [[["ugal"], [7]], [["third"], [6]], [["third"], [6]], [["fifth"], [6]], [["fourth"], [8]], [["third"], [6]], [["ugal"], [6]], [["third"], [6]], [["third"], [6]], [["second", "third"], [4, 6]]]}, "14": {"explanation": "Explanation: The neuron is looking for references to web pages or online content", "answers": ["Activating tokens: webpage (8)", "No activating tokens", "Activating tokens: search results (8), webpage (7)", "No activating tokens", "Activating tokens: email (2)", "No activating tokens", "Activating tokens: webpage (8)", "No activating tokens", "Activating tokens: webpage (8), search engine's own webpage (9)", "Activating tokens: webpage (8)"], "correct": [[[" webpage"], [2]], [[" bullets"], [2]], [[" webpage"], [2]], [[" cartridges"], [2]], [[" bullets"], [2]], [[" cartridges"], [2]], [[" webpage"], [2]], [[" bullets"], [2]], [[" webpage"], [2]], [[" webpage"], [2]]]}, "15": {"explanation": "Explanation: The neuron is looking for prepositions in a sentence", "answers": ["Activating tokens: for (2), in (2)", "Activating tokens: in (2), on (1), with (0)", "Activating tokens: in (2), at (1), with (1)", "Activating tokens: with (2), of (2)", "Activating tokens: to (2), among (1), of (2), in (1)", "Activating tokens: of (2), through (1), with (0), on (1)", "Activating tokens: by (2), with (2), of (1)", "Activating tokens: up (2), on (2), of (1), in (1)", "Activating tokens: of (2), with (0), at (4), up (4)", "Activating tokens: through (2), of, with, to, out, of, about, for"], "correct": [[[" in"], [1]], [[" in"], [1]], [[" in"], [1]], [[" for", " $", " in"], [0, 0, 1]], [["holder", " to", " of"], [2, 0, 0]], [[" through", " a"], [1, 0]], [[" in", " the"], [1, 0]], [["out", " on", " the", "."], [1, 1, 0, 0]], [["."], [1]], [["holder", " a", " going", " out", " of", " the", " the", " is"], [2, 0, 0, 0, 0, 0, 0, 0]]]}, "16": {"explanation": "Explanation: The neuron is looking for the word \"tie\" in various contexts, including literal references to a physical tie or bond, as well as figurative uses such as \"ties\" between people or concepts", "answers": ["Activating tokens: ties (8)", "Activating tokens: ties (8)", "Activating tokens: ties (8)", "Activating tokens: tie (8)", "Activating tokens: tie (8), ties (0)", "Activating tokens: ties (8)", "No activating tokens", "Activating tokens: ties (8)", "Activating tokens: ties (8)", "Activating tokens: ties (8)"], "correct": [[[" ties"], [4]], [[" ties"], [4]], [[" ties"], [4]], [["tie"], [11]], [[" ties"], [4]], [[" ties"], [4]], [["tie"], [12]], [[" ties"], [4]], [[" ties"], [4]], [[" ties"], [4]]]}, "18": {"explanation": "Explanation: The neuron is looking for proper nouns related to names of organizations, publications, or titles", "answers": ["Activating tokens: Bulletin (8), Dressipi (9), London (7)", "Activating tokens: Dunedin School of Medicine (8)", "Activating tokens: Scientific (1), Cardui (1), Carduus (1), Holy Thistle (2), Lady's Thistle (2), Marian Thistle (2), Mariendistel (2), Mary Thistle (2", "Activating tokens: Billy Strayhorn (8), Freddie Hubbard (7), Milt Hinton (7), Jon Faddis (7), Curtis Fuller (7), Regina Carter (7), Andy Bey (7), Kurt Elling (7", "Activating tokens: Dian Pelangi's (8)", "Activating tokens: Philadelphia (8)", "Activating tokens: Scientology (8)", "Activating tokens: Scientology (8), L", "Activating tokens: Scientology (8), Cortana (6), Hollywood (5)", "Activating tokens: Dictionary of London (8), St"], "correct": [[[" Bulletin"], [4]], [["Scient", "ific"], [6, 1]], [["Scient", "ific"], [6, 1]], [[" Hubbard"], [11]], [[" Dian"], [6]], [[" Dian"], [6]], [[" Scientology"], [7]], [[" Scientology", " Hubbard"], [7, 11]], [[" Scientology", " Scientology"], [7, 7]], [[" Hubbard"], [11]]]}, "21": {"explanation": "Explanation: The neuron is looking for abbreviations or acronyms, specifically those that are in all capital letters (e", "answers": ["Activating tokens: WHEN (1), Browns might refer to Cleveland Browns, so NE (5)", "Activating tokens: APC (8)", "Activating tokens: J (2), CAPTURE (0), RY (0)", "Activating tokens: MOBILE (8)", "Activating tokens: ART (8)", "Activating tokens: Lecture 5 (4), PROGRAM 5 (6)", "Activating tokens: USES (5), DISCLOSURES (5), PROTECTED (5), HEALTH (5)", "Activating tokens: PC (8), MAC (8), MS (0, not all capital letters)", "Activating tokens: ART (5)", "Activating tokens: BITS (10)"], "correct": [[["ES"], [1]], [["ES"], [1]], [["URE"], [1]], [["ES"], [1]], [["URES"], [7]], [["URE"], [1]], [["URES"], [8]], [["ES"], [2]], [["URES"], [7]], [["ES"], [1]]]}, "24": {"explanation": "Explanation: The neuron is looking for specific geographic locations, particularly \"Cove\", and also the word \"disregarded\"", "answers": ["Activating tokens: McCovey Cove (10), Cove (8)", "Activating tokens: disregarded (8)", "Activating tokens: disregarded (8)", "No activating tokens", "No activating tokens", "Activating tokens: Camachee Cove (10), none for \"disregarded\" since it's not present in the document", "Activating tokens: none (no \"Cove\" found), disregarded (8)", "Activating tokens: McCovey Cove (10), SAN FRANC (8)", "Activating tokens: Cove (8)", "Activating tokens: none (no \"Cove\" and only \"disregarding\", not \"disregarded\")"], "correct": [[[" Cove"], [6]], [[" disreg"], [8]], [[" disreg"], [8]], [[" ruth"], [10]], [[" ruth", "lessness"], [10, 1]], [[" Cove"], [7]], [[" disreg", " disreg"], [7, 8]], [[" Cove"], [7]], [[" Cove"], [7]], [[" disreg"], [8]]]}, "25": {"explanation": "Explanation: The neuron is looking for words related to success or failure, such as \"failures\", \"failure\", \"fail\", and \"successful\"", "answers": ["Activating tokens: failures (8)", "Activating tokens: failures (8)", "Activating tokens: failures (8)", "Activating tokens: failure (8)", "Activating tokens: Fail (8)", "Activating tokens: failures (8), failure (8)", "Activating tokens: none", "Activating tokens: failures (8)", "Activating tokens: failures (8), fail (6)", "Activating tokens: failures (8)"], "correct": [[[" failures"], [3]], [[" failures"], [4]], [[" failures"], [3]], [["fail"], [5]], [["Fail"], [7]], [[" failures"], [3]], [["fail"], [6]], [[" failures"], [4]], [[" failures"], [3]], [[" failures"], [4]]]}, "26": {"explanation": "Explanation: The neuron is looking for the term \"robotic\"", "answers": ["Activating tokens: robotic (10)", "Activating tokens: robotic (10)", "Activating tokens: robot (2), robotic (0)", "No activating tokens", "Activating tokens: robotic (10)", "Activating tokens: robotic (10)", "Activating tokens: robotic (10)", "Activating tokens: robot (8)", "Activating tokens: robotic (10)", "Activating tokens: robotisation (8), robots (8)"], "correct": [[[" robotic"], [6]], [[" robotic"], [6]], [[" robot", " robot"], [5, 5]], [[" Titan"], [5]], [[" robotic"], [7]], [[" robotic"], [6]], [[" robotic"], [7]], [[" robot"], [5]], [[" robotic"], [6]], [[" robot", " robot", " robots"], [4, 5, 4]]]}, "27": {"explanation": "Explanation: The neuron is looking for references to the state of Massachusetts or institutions located in Massachusetts", "answers": ["Activating tokens: Massachusetts (8)", "Activating tokens: Massachusetts (8), Amherst College (7)", "Activating tokens: Massachusetts (8), Massachusetts Institute of Technology (9)", "Activating tokens: Wellesley, Massachusetts (10), Massachusetts Institute of Technology (MIT) (8)", "Activating tokens: Massachusetts (8), Boston (7), State House (6), Beacon Hill (5)", "Activating tokens: Massachusetts (8)", "Activating tokens: Massachusetts (8), Massachusetts General Hospital (9), Boston (7)", "Activating tokens: Massachusetts (8), MIT (8)", "Activating tokens: Massachusetts (8)", "Activating tokens: Massachusetts (8)"], "correct": [[[" Massachusetts"], [8]], [[" Massachusetts"], [8]], [["achusetts"], [13]], [[" Massachusetts", " Massachusetts"], [7, 8]], [[" Massachusetts"], [8]], [["achusetts"], [12]], [[" Massachusetts"], [8]], [[" Massachusetts"], [8]], [[" Massachusetts"], [8]], [[" Massachusetts"], [8]]]}, "29": {"explanation": "Explanation: The neuron is looking for dashes or hyphens used to separate items in a list or to indicate a range", "answers": ["Activating tokens: omega-6, omega-3 (2)", "Activating tokens: A-D (8), - (7)", "Activating tokens: - (2), ( (2), ) (2)", "Activating tokens: glucose- (5), \u03b2-cell (5), Stem Cell- (5), In-stem (5), -(hyphen in \"J Surg Res237, 22-29\") (8)", "Activating tokens: bricb-mak (8), mi-forllis (8)", "Activating tokens: -, - , -, -, -, : (10)", "Activating tokens: - (mak-) (2)", "Activating tokens: ; (5), - (1), ; (6)", "Activating tokens: - (1)", "Activating tokens: - (3), : (2)"], "correct": [[["-", "-"], [0, 1]], [["-", "-", "-"], [0, 1, 1]], [["-", "-"], [1, 1]], [["-", "-", "-"], [1, 0, 0]], [["-", "-"], [0, 1]], [["-", "-", "-", "-", "-"], [0, 0, 1, 1, 1]], [["-", "-"], [1, 1]], [["-", "-"], [1, 1]], [["-"], [1]], [["-", "-", "-"], [0, 0, 1]]]}, "31": {"explanation": "Explanation: The neuron is looking for the concept of \"manufacturing\" in a document", "answers": ["Activating tokens: manufacturing (8)", "Activating tokens: manufacturing (8)", "Activating tokens: manufacturing (10), factories (8)", "Activating tokens: manufacturing (10), manufacturing (8)", "Activating tokens: manufacturing (8)", "Activating tokens: manufacturing (8)", "Activating tokens: manufacturing (8)", "Activating tokens: manufacturing (8)", "Activating tokens: manufacturing (8), production (6)", "Activating tokens: manufacturing (8)"], "correct": [[[" manufacturing"], [8]], [[" manufacturing"], [8]], [[" manufacturing", " manufacturing"], [9, 8]], [[" manufacturing", " manufacturing", " manufacturing"], [7, 8, 8]], [[" manufacturing"], [8]], [[" manufacturing"], [8]], [[" manufacturing"], [8]], [[" manufacturing"], [9]], [[" manufacturing"], [9]], [[" manufacturing"], [8]]]}, "32": {"explanation": "Explanation: The neuron is looking for the word \"prev\" or its variants, such as \"prevails\", which are related to the concept of preceding or coming before something", "answers": ["Activating tokens: Inj Prev (10)", "Activating tokens: prevails (8)", "Activating tokens: previa (10)", "Activating tokens: Prevailed (10), Prev (10)", "Activating tokens: Prev (10)", "Activating tokens: Prev (8)", "Activating tokens: prevails (8)", "Activating tokens: Prev (10)", "Activating tokens: Prevents (8)", "Activating tokens: previlege (8)"], "correct": [[[" Prev"], [0]], [[" prev"], [1]], [[" prev"], [1]], [[" Prev", " Prev", " Prev"], [0, 0, 0]], [[" Prev"], [0]], [[" Prev"], [0]], [[" prev"], [1]], [[" Prev"], [0]], [[" Prev"], [0]], [[" prev"], [1]]]}, "33": {"explanation": "Explanation: The neuron is looking for references to visual media, specifically images", "answers": ["Activating tokens: Photo (8), \"Red and Yellow Curve\", Digital Print (8)", "No activating tokens", "Activating tokens: Jupiterimages/Stockbyte/ Getty Images (10)", "Activating tokens: Images (8), dashcam (9)", "Activating tokens: Images (8),", "Activating tokens: Images (8), Getty Images (9)", "Activating tokens: Photo (8), Getty Images (6)", "Activating tokens: saw (4)", "Activating tokens: images (8), image (7)", "Activating tokens: Photo (2)"], "correct": [[[" Images"], [4]], [["bis"], [1]], [[" Images"], [5]], [[" Images"], [4]], [[" Images"], [0]], [[" Images"], [4]], [[" Images"], [5]], [[" Press"], [2]], [[" Image"], [0]], [[" Images"], [5]]]}, "34": {"explanation": "Explanation: The neuron is looking for the word \"Silver\"", "answers": ["Activating tokens: Silver (10)", "Activating tokens: Silver (10)", "Activating tokens: Silver (10)", "Activating tokens: Silver (10)", "Activating tokens: Silver (10)", "Activating tokens: Silver (10)", "Activating tokens: Silver (10)", "Activating tokens: Silver (2), Silver King (2)", "Activating tokens: Silverman (8), Silverman's (8)", "Activating tokens: Silverman (10)"], "correct": [[[" Silver"], [10]], [[" Silver"], [9]], [[" Silver"], [9]], [[" Silver"], [9]], [[" Silver"], [9]], [[" Silver"], [9]], [[" Silver"], [10]], [[" Silver", " Silver"], [10, 10]], [[" Silver", " Silver"], [9, 9]], [[" Silver"], [10]]]}, "35": {"explanation": "Explanation: The neuron is looking for words related to a type of room or space, specifically \"Studio\" and \"Lounge\"", "answers": ["Activating tokens: Studio (10),", "Activating tokens: lounge (8)", "Activating tokens: Lounge (8), Hall (10)", "Activating tokens: Lounge (8)", "Activating tokens: studios (8), lounge (9)", "Activating tokens: Lounge (8)", "Activating tokens: lounge (8)", "Activating tokens: Lounge (8)", "Activating tokens: Studio (8)", "Activating tokens: Lounge (8)"], "correct": [[["Studio"], [5]], [[" lounge"], [5]], [[" lounge"], [4]], [[" lounge"], [5]], [[" studios", " lounge"], [3, 5]], [[" Lounge"], [5]], [[" lounge"], [5]], [[" lounge"], [5]], [["Studio"], [5]], [[" lounge"], [5]]]}, "36": {"explanation": "Explanation: The neuron is looking for words related to beauty pageants or competitions", "answers": ["Activating tokens: pageant (8), Miss BC (9)", "Activating tokens: pageant (8)", "Activating tokens: Miss (8), contestants (7)", "No activating tokens", "Activating tokens: pageant (8), sponsor (4)", "No activating tokens", "Activating tokens: championship (8)", "Activating tokens: pageant (8)", "Activating tokens: Miss (8)", "No activating tokens"], "correct": [[[" pageant"], [5]], [[" pageant"], [5]], [[" contestants"], [4]], [[" Shades"], [4]], [[" pageant"], [5]], [[" Shades"], [4]], [[" contestants"], [4]], [[" pageant"], [5]], [[" contestants"], [4]], [[" Shades", " Shades"], [4, 4]]]}, "38": {"explanation": "Explanation: The neuron is looking for Chinese characters", "answers": ["Activating tokens: \u4eba (10)", "Activating tokens: \ufffd\ufffd\ufffd (10)", "Activating tokens: \u5927\u5b66 (8), \u5148\u4fee (6), \u8003\u8bd5 (6), \u7b49 (4), \u5e2e\u52a9 (5), \u5b66\u751f (7), \u6210\u529f (7), \u5ea6\u8fc7 (5), \u8fdb\u5165 (5),", "Activating tokens: \u53cc\u82b1\u8349 (10)", "Activating tokens: \u53cb\uff0c\u9650\u5973\u751f\u3002 \u8b1d\u8b1d! (10)", "Activating tokens: \u6bb5 (10), \u5927\u5b66 (10), \u7406\u4e8b\u4f1a (10), \u901a\u8fc7 (10), \u7814\u7a76 (10), \u5021\u8bae (10), \u7b49 (10), \u6e20\u9053 (10), \u5145\u5206 (", "Activating tokens: \u53f0 (10), \u5357 (8), \u5927 (8), \u6cb9 (8), \u8292 (8)", "Activating tokens: \u3002, \uff5e (10)", "Activating tokens:  (10),  (10),  (10),  (10)", "Activating tokens: \u56e0\u70ba (8), \u7562\u696d (8)"], "correct": [[["\ufffd"], [16]], [["\ufffd"], [15]], [["\ufffd"], [16]], [["\ufffd"], [15]], [["\ufffd"], [15]], [["\ufffd"], [16]], [["\ufffd"], [14]], [["\ufffd"], [16]], [["\ufffd", "\ufffd"], [16, 16]], [["\ufffd"], [16]]]}, "39": {"explanation": "Explanation: The neuron is looking for words related to \"tidbit\" or \"tidy\", possibly indicating a focus on small pieces of information or organization", "answers": ["Activating tokens: compact (4)", "Activating tokens: tidings (8)", "Activating tokens: tidbits (8)", "Activating tokens: tidiness (8)", "Activating tokens: tidbit (8)", "Activating tokens: bits (5)", "Activating tokens: tidbits (8)", "Activating tokens: tidings (8)", "Activating tokens: tidying (8), tidy (7)", "Activating tokens: tidbits (8)"], "correct": [[[" clos"], [5]], [[" tid"], [17]], [[" tid"], [17]], [[" tid", "iness"], [18, 1]], [[" tid"], [17]], [[" clos"], [4]], [[" tid"], [18]], [[" tid"], [17]], [[" tid"], [18]], [[" tid"], [18]]]}, "41": {"explanation": "Explanation: The neuron is looking for the word \"Mans\" or variations of it, likely referring to proper nouns such as places (e", "answers": ["Activating tokens: Mansfield (8)", "Activating tokens: Mansfield (8), Mans (8)", "Activating tokens: Le Mans (8), Mans (8)", "Activating tokens: Mansouri (10), Mansouri (10)", "Activating tokens: Mansplaining (8), Mans (8)", "No activating tokens", "No activating tokens", "Activating tokens: Mansfield (8), Mans (8)", "Activating tokens: Mans (0)", "Activating tokens: Mansfield (8)"], "correct": [[[" Mans"], [6]], [[" Mans"], [6]], [[" Mans"], [4]], [[" Mans", " Mans"], [5, 5]], [[" Mans"], [6]], [["mans"], [4]], [[" comrades"], [5]], [[" Mans"], [5]], [["mans"], [4]], [[" Mans"], [6]]]}, "42": {"explanation": "Explanation: The neuron is looking for sentences that specify what is included in a list or description", "answers": ["Activating tokens: \"will receive the HTC Scribe\u2122 digital pen ", "Activating tokens: These include (8)", "Activating tokens: \"some of them don't even include photos\" (8)", "Activating tokens: These numbers do not include the children in the nursery (10)", "Activating tokens: e", "Activating tokens: you get access to the above-mentioned grove of redwoods, a (8)", "Activating tokens: who enjoy Filet Mignons also enjoy", "Activating tokens: include (2)", "Activating tokens: including (8)", "Activating tokens: \"activities\", \"adventures\" (8), \"include\" (9)"], "correct": [[[" include"], [5]], [[" include"], [5]], [[" include"], [6]], [[" include"], [5]], [[" include"], [5]], [[" include"], [5]], [[" include"], [6]], [[" include", " include"], [5, 5]], [[" include"], [5]], [[" include"], [6]]]}, "45": {"explanation": "Explanation: The neuron is looking for the word \"apple\"", "answers": ["Activating tokens: apple (8)", "Activating tokens: apple (10)", "Activating tokens: apple (10)", "Activating tokens: apple (10)", "Activating tokens: apple (8)", "Activating tokens: apple (10)", "Activating tokens: apple (4), apple (4), Apple (10), apple (4)", "Activating tokens: Apple (8)", "Activating tokens: apple (8)", "Activating tokens: apple (10)"], "correct": [[[" apple"], [7]], [[" apple"], [7]], [[" apple"], [7]], [[" apple"], [7]], [[" apple"], [7]], [[" apple"], [7]], [[" apple", "apple", "Apple", " apple"], [7, 6, 4, 7]], [[" apple"], [7]], [[" apple"], [7]], [[" apple"], [7]]]}, "46": {"explanation": "Explanation: The neuron is looking for words related to pleading or supplication, such as \"begging\", and also words related to natural or unprocessed things, like \"organic\"", "answers": ["Activating tokens: organic (8)", "Activating tokens: begging (8)", "Activating tokens: begging (8)", "Activating tokens: organic (8)", "Activating tokens: organic (8)", "Activating tokens: organic (8)", "Activating tokens: begging (8)", "Activating tokens: begging (8)", "No activating tokens", "Activating tokens: organic (8), organic (8)"], "correct": [[[" organic"], [5]], [[" begging"], [6]], [[" begging"], [6]], [[" organic"], [6]], [[" organic"], [5]], [[" organic"], [5]], [[" begging"], [6]], [[" begging"], [6]], [[" immature"], [6]], [[" organic", " organic"], [5, 5]]]}, "47": {"explanation": "Explanation: The neuron is looking for the token \"dist\", which is often an abbreviation for \"district\" or \"distribution\"", "answers": ["Activating tokens: dist (8)", "Activating tokens: dist (10)", "Activating tokens: distribution (8), distribution (10)", "Activating tokens: dist (10)", "Activating tokens: dist (10)", "Activating tokens: dist (8)", "Activating tokens: dist (10)", "No activating tokens", "Activating tokens: dist (10)", "Activating tokens: distinct (5)"], "correct": [[["dist"], [2]], [["dist"], [2]], [["dist"], [2]], [["dist"], [2]], [["dist"], [2]], [["dist"], [3]], [["dist"], [2]], [["dist"], [2]], [["dist"], [2]], [["dist"], [3]]]}, "48": {"explanation": "Explanation: The neuron is looking for specific names or parts of names, such as \"yll\" (likely part of Phyllis) or \"ucl\" (possibly part of a name like Euclid), rather than general concepts or keywords", "answers": ["Activating tokens: Euclid (8), Vodkin (7)", "Activating tokens: Reinland (8)", "No activating tokens", "Activating tokens: Phyllis (8)", "Activating tokens: Phyllis (8)", "Activating tokens: Phyll (8)", "Activating tokens: Jyll (8)", "Activating tokens: ucl (8)", "Activating tokens: Jekyll (8), Hyde (8), Louis (7)", "Activating tokens: Phyll (8)"], "correct": [[["ucl"], [8]], [["yll"], [11]], [["yll"], [11]], [["yll"], [11]], [["yll"], [11]], [["yll"], [12]], [["yll"], [11]], [["ucl"], [7]], [["yll"], [11]], [["yll"], [12]]]}, "50": {"explanation": "Explanation: The neuron is looking for verbs or phrases that indicate action, creation, or instruction, specifically \"Make\" and \"frameworks\"", "answers": ["Activating tokens: build (8), repair (6), pulling (7), cable (6)", "Activating tokens: make (0), frameworks (8)", "Activating tokens: make (0), frameworks (8)", "Activating tokens: make (0), frameworks (8)", "Activating tokens: Make (10), writing (6)", "Activating tokens: Make (8), Design (6)", "Activating tokens: compare (4), including (3), intend (3), frameworks (8)", "Activating tokens: make (8), frameworks (8)", "Activating tokens: apply (8), will make (10)", "Activating tokens: Make (10), make (8)"], "correct": [[[" frameworks"], [4]], [[" frameworks"], [4]], [[" frameworks"], [4]], [["Frameworks"], [11]], [["Make"], [4]], [["Make"], [4]], [[" frameworks"], [4]], [[" frameworks"], [4]], [[" frameworks"], [4]], [["Make"], [4]]]}, "52": {"explanation": "Explanation: The neuron is looking for the term \"cargo\"", "answers": ["Activating tokens: cargo (10)", "Activating tokens: cargo (10)", "Activating tokens: cargo (8)", "Activating tokens: cargo (10)", "Activating tokens: cargo (3), Cargo (3)", "Activating tokens: cargo (8)", "Activating tokens: cargo (10)", "Activating tokens: cargo (8)", "Activating tokens: cargo (3), cargo (10)", "Activating tokens: cargo (10)"], "correct": [[[" cargo"], [6]], [[" cargo"], [6]], [[" cargo"], [6]], [[" cargo"], [6]], [[" cargo"], [6]], [[" cargo"], [6]], [[" cargo", " cargo"], [5, 6]], [[" cargo"], [6]], [[" cargo", " cargo", " cargo"], [6, 6, 6]], [[" cargo"], [6]]]}, "54": {"explanation": "Explanation: The neuron is looking for the suffix \"-ent\" in words", "answers": ["Activating tokens: violent (8), fraudulent (8)", "Activating tokens: insolent (8)", "Activating tokens: Violation (8)", "Activating tokens:  destroying (8)", "Activating tokens: insurgent (8)", "Activating tokens: violent (8), chairman (2), chairman (2)", "Activating tokens: dependent (0), but actually \"assent\" is not present, so no activation", "Activating tokens: perfect  (5), associated  (8)", "Activating tokens: latent (8)", "Activating tokens: present (8)"], "correct": [[["ent"], [6]], [["ent"], [1]], [["ation"], [1]], [["wolf"], [0]], [["ent"], [1]], [["ent"], [6]], [["ents"], [1]], [["ors"], [1]], [["ent"], [1]], [["ent"], [0]]]}, "55": {"explanation": "Explanation: The neuron is looking for the word \"Puerto\"", "answers": ["Activating tokens: Puerto (10)", "Activating tokens: Puerto (10)", "Activating tokens: Puerto (10)", "Activating tokens: Puerto (10)", "Activating tokens: Puerto (10)", "Activating tokens: Puerto (10)", "Activating tokens: Puerto (10)", "Activating tokens: Puerto (10)", "Activating tokens: Puerto (10)", "Activating tokens: Puerto (10)"], "correct": [[[" Puerto"], [5]], [[" Puerto"], [5]], [[" Puerto"], [5]], [[" Puerto"], [5]], [[" Puerto"], [5]], [[" Puerto"], [5]], [[" Puerto"], [5]], [[" Puerto"], [5]], [[" Puerto"], [5]], [[" Puerto"], [5]]]}, "56": {"explanation": "Explanation: The neuron is looking for specific numerical values, particularly three-digit numbers (108 and 104) in the text", "answers": ["Activating tokens: 10760 (8), 10816 (10), 1084 (9)", "Activating tokens: 108 (10)", "Activating tokens: 108 (10)", "Activating tokens: 108 (10), 104 (10)", "Activating tokens: 108 (10), 107 (9)", "Activating tokens: 104 (10), 16879169 (10)", "Activating tokens: 108 (10), 93 (8), 200 (9), 29 (7), 24 (6), 10 (5)", "Activating tokens: 108 (10), 235 (6)", "Activating tokens: 104 (10), 108 (10)", "Activating tokens: 102 (8), 108 (10)"], "correct": [[[" 108"], [5]], [[" 108"], [5]], [[" 108"], [5]], [[" 108", " 104", " 104"], [5, 2, 2]], [[" 108"], [5]], [["104"], [3]], [[" 108", " 108"], [5, 5]], [[" 108"], [5]], [[" 104", " 108", " 108"], [2, 5, 6]], [[" 108"], [5]]]}, "58": {"explanation": "Explanation: The neuron is looking for punctuation marks or common function words that do not carry significant meaning in a sentence", "answers": ["Activating tokens: and (2), to (1), the (3)", "Activating tokens: and (4), of (2), on (2), the (3)", "Activating tokens: et (1), at (2), of (2), and (3), the (4), a (2)", "Activating tokens: in (2), and (1), a (1), of (1), to (1)", "Activating tokens: ", "Activating tokens: of (2), and (1)", "Activating tokens: with (2), to (1), and (3), or (1)", "Activating tokens: and (2), but (2), to (1), a (2), of (2), it (1)", "Activating tokens: and (2), to (1), in (1), of (2), that (1), a (1)", "Activating tokens: and (4), or (2), a (3), the (2)"], "correct": [[["Pin"], [1]], [[" and", " will", " be", " in", " of", " and", ",", " on", " the", ".", " will", " also", " be", " at", " six", ":", ",", ",", ",", " A", ","], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], [["At", " A", " for", " and", " The", " was", " of", " the", "'s", " to", " have", " my"], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], [[" the", " took", " in", ".", " OR"], [0, 0, 0, 0, 1]], [["at", "at"], [1, 0]], [[" and", " all", " over", " the", " of", " that", ".", "\n", "A", " U"], [0, 0, 1, 1, 0, 0, 0, 0, 0, 0]], [[" via", ",", " the", " to", " off", " to", " other", ".", "\n", " to", "'s", "-", " and", " (", " out", ","], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]], [[",", " it", " was", " a", " most", " of", "'s", "at", " because", " her", " as", "\n", " up", " more", ".", " In", " were", " in", " were", " its"], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], [[" and", " in", " of", " his", ".", " me", " you", "?"], [0, 0, 1, 0, 0, 0, 0, 0]], [[" and", " get", " the", "-", "with", "-", "-", "ist", "."], [0, 0, 0, 0, 0, 0, 0, 1, 0]]]}, "60": {"explanation": "Explanation: The neuron is looking for verb suffixes (-ed, -es, -ing) that indicate grammatical tense or aspect", "answers": ["Activating tokens: shot (8), saw (7), happened (6), were (5), stampeded (9), began (7), firing (8), wounded (7)", "Activating tokens: whisking (8), add (4), begin (4), dissolve (4)", "Activating tokens: tried (8), heard (6), came (5)", "Activating tokens: whisking (8), cook (7), remove (6), whisk (5)", "Activating tokens: presents (6), inspired (8), inspire (7), accompanied (6)", "Activating tokens: was (5), wanting (7), found (8), exhale (9)", "Activating tokens: blows (7), becomes (8), put (6)", "Activating tokens: remain (6), established (8), extended (8), invoiced (7), will (5)", "Activating tokens: lived (8), celebrating (7), purchase (6)", "Activating tokens: have (5), been (5), including (4), teaching (4), imagine (5), lounging (6), sleeping (6)"], "correct": [[["es"], [2]], [["ing", "ing"], [2, 2]], [["es"], [2]], [["ing"], [2]], [["s"], [1]], [["ed"], [1]], [["ing"], [1]], [["ing"], [1]], [["es"], [2]], [["ing"], [2]]]}, "61": {"explanation": "Explanation: The neuron is looking for words related to harm or wrongdoing, such as injury, insult, casualty, etc", "answers": ["Activating tokens: affront (8), insult (8)", "Activating tokens: casualty (8), injury (0)", "Activating tokens: injury (8)", "Activating tokens: insult (8), annoyance (4)", "Activating tokens: casualty (8)", "Activating tokens: insult (8), injury (9)", "Activating tokens: injury (8), accident (7)", "Activating tokens: injury (8), insult (8)", "Activating tokens: insult (8), injury (8)", "Activating tokens: insult (8)"], "correct": [[[" insult"], [8]], [[" casualty"], [7]], [[" injury"], [5]], [[" insult"], [9]], [[" casualty"], [7]], [[" insult", " injury"], [8, 4]], [[" injury"], [4]], [[" insult", " injury"], [9, 4]], [[" insult", " injury"], [8, 4]], [[" insult"], [8]]]}, "62": {"explanation": "Explanation: The neuron is looking for the abbreviation \"WS\", which likely stands for a specific term or acronym in different contexts", "answers": ["Activating tokens: FWS (10)", "Activating tokens: USFWS (8)", "Activating tokens: WS (10)", "Activating tokens: WS (10)", "Activating tokens: WS (10), WSJ (10)", "No activating tokens", "Activating tokens: WS (10)", "No activating tokens", "No activating tokens", "Activating tokens: OWS (8)"], "correct": [[["WS"], [6]], [["WS"], [6]], [["WS"], [5]], [["WS"], [5]], [["WS"], [5]], [["WS"], [6]], [["WS"], [6]], [["WS"], [7]], [["WS"], [6]], [["WS"], [6]]]}, "63": {"explanation": "Explanation: The neuron is looking for words related to inconvenience, trouble, or annoyance", "answers": ["Activating tokens: pain (8), hassle (9)", "Activating tokens: none", "Activating tokens: noise (4)", "Activating tokens: hassle-free (8)", "Activating tokens: difficulty (4), hassle (7)", "Activating tokens: hassle (8)", "Activating tokens: disconcerting (8), embarrassment (9)", "Activating tokens: hassle (8)", "Activating tokens: hassle (8), risk (6)", "Activating tokens: hassle (8)"], "correct": [[[" hassle"], [6]], [[" glare", " glare"], [7, 7]], [[" glare"], [7]], [[" hassle"], [6]], [[" hassle"], [6]], [[" hassle"], [6]], [[" glare"], [7]], [[" hassle"], [6]], [[" hassle"], [6]], [[" hassle"], [6]]]}, "64": {"explanation": "Explanation: The neuron is looking for the English words \"ant\" and \"ants\", regardless of context", "answers": ["No activating tokens", "No activating tokens", "No activating tokens", "No activating tokens", "No activating tokens", "No activating tokens", "No activating tokens", "No activating tokens", "No activating tokens", "No activating tokens"], "correct": [[["ant"], [4]], [["ants"], [2]], [["ant", "ant"], [2, 2]], [["ant"], [4]], [["ant"], [4]], [["ants"], [2]], [["ant"], [4]], [["ant"], [4]], [["ants"], [2]], [["ant"], [4]]]}, "65": {"explanation": "Explanation: The neuron is looking for the word \"cliff\"", "answers": ["Activating tokens: cliff (10)", "Activating tokens: cliffhanger (8), cliff (10)", "Activating tokens: \"cliff\" (10)", "Activating tokens: cliff (2), cliffhangers (2)", "Activating tokens: cliff (10)", "Activating tokens: cliff (10)", "Activating tokens: cliff (2)", "Activating tokens: Cliff (8)", "Activating tokens: Cliff (10)", "Activating tokens: cliff (10)"], "correct": [[[" cliff"], [14]], [[" cliff"], [15]], [[" cliff"], [13]], [[" cliff", " cliff"], [16, 16]], [[" cliff"], [14]], [[" cliff"], [14]], [[" cliff", " cliff"], [15, 15]], [[" Cliff"], [4]], [[" Cliff"], [4]], [[" cliff"], [13]]]}, "66": {"explanation": "Explanation: The neuron is looking for words related to change or transformation, such as \"redesigned\" or names that contain \"Emer\", which may imply emergence or change", "answers": ["Activating tokens: Emergent (8)", "Activating tokens: redesigned (8)", "Activating tokens: Emer (8)", "Activating tokens: Emery (4)", "Activating tokens: Emer (5)", "Activating tokens: redesigned (8)", "Activating tokens: redesigned (8)", "Activating tokens: Emery (8)", "Activating tokens: Emery (8)", "Activating tokens: Emergencies (8), Emer (7)"], "correct": [[[" Emer"], [4]], [[" redesigned"], [5]], [[" Emer"], [4]], [[" Emer"], [4]], [[" Emir"], [7]], [[" redesigned"], [5]], [[" redesigned"], [5]], [[" Emer"], [5]], [[" Emer", " Emer"], [4, 4]], [[" Emer"], [4]]]}, "67": {"explanation": "Explanation: The neuron is looking for the verb \"blown\" in various contexts, including literal and figurative senses", "answers": ["Activating tokens: blown (10)", "Activating tokens: was blown (10)", "Activating tokens: blown (8)", "No activating tokens", "Activating tokens: blows (8), blown (10)", "Activating tokens: blown (8)", "Activating tokens: blown (8)", "Activating tokens: blown (8)", "Activating tokens: blown (2), blown (8)", "Activating tokens: blown (8)"], "correct": [[[" blown"], [10]], [[" blown"], [9]], [[" blown"], [10]], [["tailed"], [9]], [[" blown"], [10]], [[" blown"], [10]], [[" blown"], [9]], [[" blown"], [10]], [[" blown", " blown"], [9, 9]], [[" blown"], [9]]]}, "69": {"explanation": "Explanation: The neuron is looking for specific surname suffixes, such as \"ley\", \"ana\", or \"man\"", "answers": ["Activating tokens: Kimberley (8)", "Activating tokens: Feinman (8), Bernanke (8)", "Activating tokens: man (Feinman) (8)", "No activating tokens", "No activating tokens", "No activating tokens", "Activating tokens: Dumas (8), Kimberley (8)", "Activating tokens: Kimberley (8)", "No activating tokens", "Activating tokens: Saylor (8)"], "correct": [[["ley"], [6]], [["man"], [1]], [["man"], [0]], [["land"], [1]], [["ines"], [1]], [["ana"], [1]], [["ley"], [6]], [["ley"], [6]], [["ining"], [1]], [["ley"], [6]]]}, "71": {"explanation": "Explanation: The neuron is looking for the concept of discussion, argumentation, or consideration of different viewpoints, often in a formal setting", "answers": ["Activating tokens: debate (8), squabbled (7), argued (7)", "Activating tokens: debate (8), discussion is implied in \"matters of great national concern\" and \"constitution amendment\" (6)", "Activating tokens: debate (8), debate (8)", "Activating tokens: debates (8)", "Activating tokens: debate (8), discussion is implied in \"present a new deal\" and \"focused on this point\", but it's not as strong of a match, so let's say (4)", "Activating tokens: debate (8)", "Activating tokens: debating (8)", "Activating tokens: debate (8)", "Activating tokens: debate (8)", "Activating tokens: debates (8)"], "correct": [[[" debate"], [2]], [[" debate"], [1]], [[" debate", " debate"], [1, 1]], [[" debates", "deb"], [2, 1]], [[" debate"], [2]], [[" debate"], [1]], [[" debating"], [3]], [[" debate"], [2]], [[" debate"], [1]], [[" debates"], [2]]]}, "73": {"explanation": "Explanation: The neuron is looking for the word \"major\" in various contexts, often indicating importance or significance", "answers": ["Activating tokens: Major (10)", "Activating tokens: major (8)", "Activating tokens: Major (8)", "Activating tokens: major (8)", "Activating tokens: Major (8)", "Activating tokens: Major (8)", "Activating tokens: major (8)", "Activating tokens: Major (8)", "Activating tokens: majoring (8)", "Activating tokens: major (8)"], "correct": [[["Major"], [7]], [["major"], [1]], [["Major"], [7]], [["major"], [1]], [["Major"], [7]], [["Major"], [6]], [["major"], [1]], [["Major"], [8]], [["major"], [1]], [["major"], [1]]]}, "74": {"explanation": "Explanation: The neuron is looking for the token \"reek\" or words that contain it, such as \"Greek\"", "answers": ["Activating tokens: Greek (10), Greek (10)", "Activating tokens: Creek (2)", "Activating tokens: Greek (2), greek (1)", "Activating tokens: greek (8)", "Activating tokens: greek (8)", "Activating tokens: greek (3), greek (5)", "Activating tokens: Greek (10), Greek (10)", "Activating tokens: Greek (8)", "Activating tokens: Greek (8), Greek (8)", "Activating tokens: reek (10), Greeks (8), Greek (8)"], "correct": [[["reek", "reek"], [16, 15]], [["reek"], [15]], [["reek", "reek"], [14, 16]], [["reek"], [16]], [["reek"], [15]], [["reek", "reek", "reek"], [15, 15, 15]], [["reek", "reek", "reek", "reek"], [15, 15, 15, 15]], [["reek"], [16]], [["reek"], [16]], [["reek", "reek", "reek"], [13, 15, 15]]]}, "75": {"explanation": "Explanation: The neuron is looking for the word \"during\" which indicates a specific time or period when an action takes place", "answers": ["Activating tokens: During (10)", "Activating tokens: during (8)", "Activating tokens: during (8)", "Activating tokens: during (8)", "Activating tokens: during (8)", "Activating tokens: during (8)", "Activating tokens: during (8)", "Activating tokens: During (10)", "Activating tokens: During (10)", "Activating tokens: During (10)"], "correct": [[[" During"], [3]], [[" during"], [3]], [[" during"], [4]], [[" during"], [4]], [[" during"], [3]], [[" during"], [4]], [[" During"], [3]], [[" During"], [4]], [[" During"], [3]], [["During"], [3]]]}, "79": {"explanation": "Explanation: The neuron is looking for adverbs ending in \"-ately\"", "answers": ["Activating tokens: wearily (8), sooner (6)", "Activating tokens: lately (8)", "No activating tokens", "Activating tokens: wearily (8), quickly (7)", "Activating tokens: briefly (8)", "Activating tokens: summarily (8)", "No activating tokens", "Activating tokens: lately (8)", "Activating tokens: momentarily (8)", "Activating tokens: equally (8)"], "correct": [[["arily"], [10]], [["ately"], [1]], [["arily"], [1]], [["arily"], [9]], [["arily"], [6]], [["arily"], [6]], [["arily"], [8]], [["ately"], [1]], [["arily"], [5]], [["ately"], [1]]]}, "80": {"explanation": "Explanation: The neuron is looking for specific proper nouns or abbreviations, such as \"Arc\" (likely referring to ArcGIS), \"DEF\", and chemical symbols like \"As\" for arsenic", "answers": ["Activating tokens: DEF (10)", "No activating tokens", "Activating tokens: ArcGIS (10), As (0)", "Activating tokens: Arc (8)", "Activating tokens: As (0)", "Activating tokens: DEF (10)", "Activating tokens: ArcGIS (8)", "Activating tokens: Arcadia (8)", "Activating tokens: Arc (10)", "No activating tokens"], "correct": [[[" DEF"], [3]], [[" arcane"], [4]], [["Arc"], [8]], [["Arc"], [8]], [[" arcane"], [4]], [[" DEF"], [3]], [["Arc"], [8]], [["Arc"], [8]], [["Arc"], [7]], [[" arcane"], [4]]]}, "81": {"explanation": "Explanation: The neuron is looking for specific abbreviations or prefixes related to proper nouns, such as \"Aut\" (Automatic Data Processing, Autumn), \"phot\" (photobucket, photography, photographer), and \"Autism\"", "answers": ["Activating tokens: Aut (10)", "Activating tokens: phot (8)", "Activating tokens: phot (8)", "Activating tokens: Auto (8)", "Activating tokens: Autofocus (8)", "Activating tokens: phot (8)", "Activating tokens: Aut (8)", "Activating tokens: phot (8)", "Activating tokens: Aut (10)", "Activating tokens: phot (8)"], "correct": [[["Aut"], [4]], [["phot"], [9]], [["phot"], [9]], [["Aut"], [4]], [["Aut"], [4]], [["phot"], [9]], [["Aut"], [4]], [["phot"], [10]], [["Aut"], [4]], [["phot"], [10]]]}, "82": {"explanation": "Explanation: The neuron is looking for the word \"actors\" specifically", "answers": ["Activating tokens: actors (10)", "Activating tokens: actors (10)", "Activating tokens: actors (10)", "Activating tokens: actors (8)", "Activating tokens: actors (10)", "Activating tokens: actors (10)", "Activating tokens: actors (10)", "Activating tokens: actors (10)", "Activating tokens: actors (10)", "Activating tokens: actors (10)"], "correct": [[[" actors"], [7]], [[" actors"], [8]], [[" actors"], [7]], [[" actors"], [8]], [[" actors"], [7]], [[" actors"], [7]], [[" actors"], [7]], [[" actors", " actors"], [7, 7]], [[" actors"], [7]], [[" actors"], [7]]]}, "83": {"explanation": "Explanation: The neuron is looking for abbreviations or shortened forms of words, particularly those related to time (e", "answers": ["Activating tokens: yr (8)", "Activating tokens: No", "Activating tokens: ary (5)", "Activating tokens: yr (10)", "Activating tokens: ADVANTAGES (5)", "Activating tokens: [your] (2)", "Activating tokens: HD (2)", "Activating tokens: Ltd (not present in this document), but there is a \"Chairman\" which can be shortened as \"Chmn\"", "Activating tokens: \u2022\u2022 (5), \u2022\u2022\u2022 (2)", "No activating tokens"], "correct": [[[" yr"], [5]], [["mas"], [5]], [["mas"], [5]], [[" yr", " yr", " yr", " yr"], [5, 5, 5, 5]], [["mas"], [6]], [["gio"], [9]], [["mas"], [5]], [["mas"], [5]], [["mas"], [6]], [["mas"], [7]]]}, "85": {"explanation": "Explanation: The neuron is looking for words that are related to emotions or interpersonal relationships, such as \"sympathetic\" and \"\u03c6\u03af\u03bb\u03bf\" (filo, meaning friend in Greek), or words that have a strong emotional connotation", "answers": ["Activating tokens: depression (8), sympathetic (7)", "Activating tokens: sympathetic (8)", "Activating tokens: \u03c6\u03af\u03bb\u03bf (8), \u03c6\u03af\u03bb\u03b5 (8)", "Activating tokens: \u03c6\u03af\u03bb\u03bf (filo) (8)", "Activating tokens: adieux (8)", "Activating tokens: indecision (8)", "Activating tokens: sympathetic (8), depression (9)", "Activating tokens: sympathetic (8)", "Activating tokens: sympathetic (8), vendetta (7)", "Activating tokens: none"], "correct": [[[" sympathetic"], [7]], [[" sympathetic"], [8]], [["\u03b9"], [7]], [["\u03b9", "\u03b9", "\u03b9"], [7, 6, 6]], [[" fugitive"], [9]], [[" fugitive"], [8]], [[" sympathetic"], [8]], [[" sympathetic"], [8]], [[" sympathetic"], [8]], [[" fugitive"], [9]]]}, "86": {"explanation": "Explanation: The neuron is looking for the term \"youth\"", "answers": ["Activating tokens: youth (2), teens (2)", "Activating tokens: youth (10)", "Activating tokens: youth (8)", "Activating tokens: youth (8)", "Activating tokens: youth (10)", "Activating tokens: youth (10)", "Activating tokens: youth (8)", "Activating tokens: youth (8)", "Activating tokens: youth (10)", "Activating tokens: youth (8)"], "correct": [[[" teens", " teens", " youth", " Youth"], [5, 5, 10, 7]], [[" youth"], [10]], [[" youth"], [10]], [[" youth"], [10]], [[" youth"], [10]], [[" youth"], [10]], [[" youth"], [10]], [[" youth"], [10]], [[" youth"], [10]], [[" youth"], [10]]]}, "88": {"explanation": "Explanation: The neuron is looking for words that start with \"re-\" as a prefix, often indicating repetition or reversal of an action", "answers": ["Activating tokens: re-enter (8)", "Activating tokens: rejoin (8)", "Activating tokens: re- (1)", "Activating tokens: re-follow (8)", "Activating tokens: reestablish (8)", "Activating tokens: return (6), reassemble (8)", "Activating tokens: re-check (8)", "Activating tokens: re-write (8)", "Activating tokens: re-evaluate (8), revise (8), re- (5)", "Activating tokens: re-think (8), Resolving (6)"], "correct": [[[" re"], [1]], [[" re"], [2]], [[" re"], [2]], [[" re"], [2]], [[" re"], [2]], [[" re"], [2]], [[" re"], [2]], [[" re"], [2]], [[" re"], [2]], [[" re"], [1]]]}, "89": {"explanation": "Explanation: The neuron is looking for the multiplication symbol (\u00d7) used to indicate dimensions or scaling factors", "answers": ["Activating tokens: \u00d7 (10)", "Activating tokens: \u00d7 (10)", "Activating tokens: 2\u00d7 (10), 3:1 (8)", "Activating tokens: 8\u00d78 (10)", "Activating tokens: \u00d7 (10)", "Activating tokens: \u00d7 (2)", "Activating tokens: \u00d7 (10)", "Activating tokens: 2\u00d74 (10)", "Activating tokens: \u00d7 (2), x (1)", "Activating tokens: \u00d7 (10)"], "correct": [[["\u00d7"], [2]], [["\u00d7"], [2]], [["\u00d7"], [2]], [["\u00d7"], [2]], [["\u00d7"], [3]], [["\u00d7"], [2]], [["\u00d7"], [2]], [["\u00d7"], [3]], [["\u00d7"], [2]], [["\u00d7"], [3]]]}, "90": {"explanation": "Explanation: The neuron is looking for words related to emotions, attitudes, or states of mind, such as hopefulness, aspirations, and anxiety", "answers": ["Activating tokens: hopeful (8)", "Activating tokens: hopeful (8)", "Activating tokens: hopeful (8)", "Activating tokens: anxiety (0), but \"imbecile\" is related to a strong negative emotion, so I'll score it as 8", "Activating tokens: aspirations (8)", "Activating tokens: glad (4), aspirations (8)", "Activating tokens: aspirations (8), anxiety (not present, but \"scary\" is related, so 4)", "Activating tokens: aspirations (8)", "Activating tokens: hopeful (8)", "Activating tokens: aspirations (8)"], "correct": [[[" hopeful"], [9]], [[" hopeful"], [8]], [[" hopeful"], [9]], [[" hopeful"], [6]], [[" aspirations"], [6]], [[" aspirations"], [6]], [[" aspirations"], [6]], [[" aspirations"], [6]], [[" hopeful"], [9]], [[" aspirations"], [5]]]}, "92": {"explanation": "Explanation: The neuron is looking for terms related to sports, specifically gymnastics or basketball, and the concept of a \"bench\" in team sports", "answers": ["Activating tokens: bench (5)", "Activating tokens: bench (8), Pistons (6), Cavs (5)", "Activating tokens: none", "Activating tokens: gymnastics (8), fitness (6), weightlifting (6)", "Activating tokens: bench (8)", "Activating tokens: bench (2)", "Activating tokens: bench (8)", "Activating tokens: bench (8)", "No activating tokens", "Activating tokens: bench (0), but gymnastics (8)"], "correct": [[["bench"], [4]], [[" bench"], [4]], [[" gymn"], [5]], [[" gymn"], [4]], [[" bench"], [3]], [[" bench", "bench"], [1, 3]], [["bench"], [4]], [[" bench"], [3]], [["bench"], [3]], [[" gymn", " gymn"], [5, 5]]]}, "93": {"explanation": "Explanation: The neuron is looking for words related to sunlight or daytime, such as \"rise\", \"set\", \"sun\", \"sunset\", \"shine\", or \"skies\"", "answers": ["Activating tokens: sun (8)", "Activating tokens: Sunrise (8), Sunset (8)", "Activating tokens: Sunset (8)", "Activating tokens: Sun (8)", "Activating tokens: sunburn (8)", "Activating tokens: sunsets (8)", "Activating tokens: Sunshine (8)", "Activating tokens: sun (8), sunburned (9), sunlamps (7)", "Activating tokens: sunsets (8)", "Activating tokens: sunsets (8)"], "correct": [[["-", "spot"], [1, 3]], [["rise", " Sunset"], [3, 0]], [["set"], [3]], [["burn"], [3]], [["burn"], [3]], [["sets"], [3]], [["shine"], [3]], [["burn", "l", " tan", "ning"], [3, 1, 1, 0]], [["sets"], [4]], [["sets"], [3]]]}, "94": {"explanation": "Explanation: The neuron is looking for the term \"corporation\"", "answers": ["Activating tokens: corporation (8)", "Activating tokens: corporation (8)", "Activating tokens: corporation (8)", "Activating tokens: corporation (10)", "Activating tokens: corporation (10)", "Activating tokens: corporation (10)", "Activating tokens: corporation (8)", "Activating tokens: corporation (10)", "Activating tokens: corporation (2)", "Activating tokens: corporation (10)"], "correct": [[[" corporation"], [9]], [[" corporation"], [9]], [[" corporation"], [9]], [[" corporation"], [9]], [[" corporation", " corporation"], [9, 9]], [[" corporation"], [9]], [[" corporation"], [9]], [[" corporation"], [9]], [[" corporation"], [9]], [[" corporation"], [9]]]}, "95": {"explanation": "Explanation: The neuron is looking for suffixes or words related to ideas, or chemical compounds like chloride", "answers": ["Activating tokens: ide (5)", "No activating tokens", "No activating tokens", "Activating tokens: ide (4)", "Activating tokens: chloride (0), but \"mentaiko\" has a suffix \"-ko\" which is similar to chemical compound suffixes, so it gets an activation value of 2", "Activating tokens: inspiration (2)", "Activating tokens: chloride (0)", "Activating tokens: ide (-ide in \"attorney general\") (4)", "Activating tokens: TBD (5)", "Activating tokens: chloride (0), but -ide is not present"], "correct": [[["ide"], [2]], [["ide"], [2]], [[" TBD"], [2]], [["ide"], [2]], [["ide"], [2]], [[" TBD"], [2]], [["ides"], [2]], [["ide"], [2]], [[" TBD"], [2]], [["ides"], [2]]]}, "96": {"explanation": "Explanation: The neuron is looking for words related to concern or regarding something", "answers": ["Activating tokens: regarding (0), about (8)", "Activating tokens: regarding (5)", "Activating tokens: concerning (8)", "Activating tokens: concerning (8), regarding (0)", "Activating tokens: concerning (10)", "Activating tokens: Concerning (8), regarding (0, not present in the document)", "Activating tokens: regarding (0), for (2)", "Activating tokens: Concerning (8), Regarding (0, not present in the document)", "Activating tokens: regarding (8)", "No activating tokens"], "correct": [[["imeters"], [3]], [["imeters"], [3]], [["cerning"], [9]], [["cerning"], [9]], [["cerning"], [9]], [["cerning"], [9]], [["imeters", "imeters"], [3, 3]], [["cerning"], [9]], [["imeters"], [3]], [["imeters"], [3]]]}, "97": {"explanation": "Explanation: The neuron is looking for references to death rituals or ceremonies, specifically funerals", "answers": ["Activating tokens: Funeral (10), Obituaries (8), funeral (8), mortuary (8)", "Activating tokens: funeral (8)", "Activating tokens: funeral (8)", "Activating tokens: funeral (8)", "Activating tokens: funeral (8), coffin (7)", "Activating tokens: funeral (8)", "Activating tokens: funeral (8)", "Activating tokens: funeral (8), preceded in death (9), visitation (7)", "Activating tokens: funeral (8)", "Activating tokens: funeral (8), funeral Mass (9)"], "correct": [[["eral", " condolences", " funeral", " funeral"], [3, 5, 8, 8]], [[" funeral"], [8]], [[" funeral"], [8]], [[" coroner", " funeral"], [0, 8]], [[" funeral", " coffin"], [8, 5]], [[" funeral"], [8]], [[" funeral"], [8]], [[" funeral"], [8]], [[" funeral"], [8]], [[" funeral", " funeral"], [8, 8]]]}, "99": {"explanation": "Explanation: The neuron is looking for the suffix \"ews\" which often forms part of words related to news, views, or pews", "answers": ["No activating tokens", "Activating tokens: news (0), views (0), pews (0), stews (8)", "Activating tokens: news (8), views (0)", "Activating tokens: news (8)", "Activating tokens: News (8)", "No activating tokens", "Activating tokens: news (0), views (0), pews (0),ews (8)", "Activating tokens: Wikinews (8)", "Activating tokens: news (0), stews (8)", "Activating tokens: news (2)"], "correct": [[[" Tro"], [3]], [["ews"], [5]], [["ews"], [5]], [["ews"], [4]], [["ews"], [4]], [[" Tro"], [4]], [["ew", "ews"], [2, 5]], [["ews"], [4]], [["ews"], [5]], [["ews"], [4]]]}, "100": {"explanation": "Explanation: The neuron is looking for abbreviations or names that start with \"McCl\" or \"SN\"", "answers": ["Activating tokens: SN (0), McClintock (8)", "Activating tokens: DSN (8)", "Activating tokens: HSNs (8)", "Activating tokens: McClure (8), SN (0)", "Activating tokens: McClendon (8)", "Activating tokens: SNAP (8)", "Activating tokens: McClintock (8)", "Activating tokens: McClendon (8)", "Activating tokens: McClain (8)", "Activating tokens: MDL-SN (10), VM-MDL-MSVC (10), VM-MDL-VW (10)"], "correct": [[[" McCl"], [7]], [["SN"], [6]], [["SN"], [6]], [[" McCl"], [7]], [[" McCl"], [7]], [["SN"], [6]], [[" McCl"], [7]], [[" McCl"], [7]], [[" McCl"], [7]], [["SN"], [6]]]}, "101": {"explanation": "Explanation: The neuron is looking for references to people, places, or things related to Germany, such as cities (Munich, Berlin), politicians (Merkel), or nationalities (German, Germans)", "answers": ["Activating tokens: Germany (8), German (not present but implied, 6)", "Activating tokens: Germany (8), Merkel (9)", "Activating tokens: Frankfurt, Germany (10)", "Activating tokens: Germany (8), Leipzig (7), Frankfurt (7)", "Activating tokens: Berlin (8), Germany (9), Germans (not present but \"German\" could be implied from the names Haberland and Dietz)", "Activating tokens: German (8), Germany (0, not present), Chancellor Theobald von Bethmann-Hollweg (9), Andreas Hillgruber (7), General Ludendorff (7)", "Activating tokens: Germany (8), Hitler's (9)", "Activating tokens: Germany (8), Team Germany (8), Karlsruhe (6), German (not present but implied by \"Team Germany\" and \"Karlsruhe, Germany\")", "Activating tokens: Germany (8), Nazis (7)", "Activating tokens: Germany (8), German (6)"], "correct": [[[" Germany"], [6]], [[" Germany", " Merkel"], [5, 6]], [[" Frankfurt", " Germany"], [2, 6]], [[" Germany", " Frankfurt"], [5, 2]], [[" Berlin", " Germany"], [3, 6]], [[" German", " Chancellor", " German", " Germany"], [5, 2, 5, 6]], [[" Germany"], [5]], [[" Germany", " Germany"], [5, 5]], [[" Germany", " Nazis"], [5, 0]], [[" Germany", " German"], [5, 6]]]}, "103": {"explanation": "Explanation: The neuron is looking for words related to the publication or dissemination of written works, such as research studies or articles", "answers": ["Activating tokens: research (2), study, journal, published", "Activating tokens: published (8), study (7)", "Activating tokens: published (8), study (6)", "Activating tokens: published (8), reporting (7), Posted (6)", "Activating tokens: published (8), study (6), studying (6)", "Activating tokens: published (8), study (7)", "Activating tokens: published (8), study (7)", "Activating tokens: published (8), study (7)", "Activating tokens: published (8), study (7)", "Activating tokens: study (8), published (9)"], "correct": [[[" journal", " published"], [1, 3]], [[" published", " Journal"], [3, 1]], [[" published", " Journal"], [2, 1]], [[" published", " Published"], [2, 1]], [[" published"], [2]], [[" published"], [3]], [[" published"], [2]], [[" published", " colleagues"], [2, 1]], [[" published", " Journal"], [2, 0]], [[" published"], [3]]]}, "104": {"explanation": "Explanation: The neuron is looking for the word \"mass\" in various forms, including as a noun or part of another word", "answers": ["Activating tokens: landmass (8)", "Activating tokens: landmass (8)", "No activating tokens", "Activating tokens: airmass (8)", "No activating tokens", "Activating tokens: massage (8)", "Activating tokens: mass (8)", "No activating tokens", "Activating tokens: Massive (8)", "No activating tokens"], "correct": [[["mass"], [6]], [["mass"], [6]], [[" sneak"], [5]], [["mass"], [6]], [[" sneak"], [5]], [["mass"], [7]], [["mass"], [6]], [[" sneak"], [5]], [["Mass"], [5]], [[" sneak"], [5]]]}, "105": {"explanation": "Explanation: The neuron is looking for the word \"Lake\"", "answers": ["No activating tokens", "Activating tokens: Lakeland (8)", "Activating tokens: Lake (8)", "Activating tokens: Lake (2), Lake (8)", "Activating tokens: Lake (8)", "Activating tokens: Lake (2)", "Activating tokens: Lake (8), Lake Merritt (9)", "Activating tokens: Lake (2)", "Activating tokens: Lake (3), Cracker Lake (2)", "Activating tokens: Lake (8)"], "correct": [[[" traps"], [3]], [[" Lake"], [3]], [["Lake"], [4]], [["Lake", " Lake"], [4, 2]], [[" Lake"], [3]], [["Lake", " Lake"], [4, 2]], [[" Lake"], [3]], [[" Lake", " Lake"], [3, 2]], [[" Lake", "Lake"], [2, 4]], [[" Lake"], [3]]]}, "107": {"explanation": "Explanation: The neuron is looking for words related to advisory or governing bodies, such as \"Advisory\", \"Board\", \"Committee\", and \"Commission\"", "answers": ["Activating tokens: Advisory Board (10)", "Activating tokens: Advisory (8), Leadership (6)", "Activating tokens: Commission (10)", "Activating tokens: Board (8), Council (8)", "Activating tokens: Board (8)", "Activating tokens: Committee (2), Advisory", "Activating tokens: Advisory (8), Committee (8)", "Activating tokens: Advisory (8), Committee (0)", "Activating tokens: Board (8)", "Activating tokens: Committee (8)"], "correct": [[[" Advisory", " Board"], [3, 3]], [[" Advisory", " Group"], [4, 2]], [[" Advisory", " Commission", " member"], [3, 2, 1]], [[" Advisory", " Board", " Advisory", " Council"], [3, 3, 3, 3]], [[" Advisory", " Board"], [4, 3]], [[" Advisory", " Committee"], [4, 3]], [[" Advisory", " Group", " committee", " committee", " Society"], [4, 2, 1, 1, 0]], [[" Advisory", " Committee"], [4, 3]], [[" Advisory", " Board"], [4, 3]], [[" Advisory", " Committee"], [4, 3]]]}, "108": {"explanation": "Explanation: The neuron is looking for Korean characters or Hangul", "answers": ["Activating tokens: , , , , ", "No activating tokens", "Activating tokens: , , , , , ", "No activating tokens", "No activating tokens", "Activating tokens: \uac00 (2), \ub97c, \ud558\ub294, \uac83, \uc54a\uc544\uc694, \uc88b, \ud558\ub2e4 (10)", "Activating tokens: )-> (10), \uc800\ub294 (10), \ucda4 (10), \ucd94\ub294 (10), \uac78 (10), \uc88b\uc544\ud574\uc694 (10), \uc800\ub294 (10), \ucda4 (10), \ucd94\ufffd (10)", "No activating tokens", "Activating tokens:  (10), , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , ,", "Activating tokens:\uc544\uc694 (10), \uac19\uc544\uc694 (10), \uadf8 (10), \ub0a8\uc790 (10), \ud654 (10)"], "correct": [[["\ufffd", "\ufffd"], [2, 2]], [["\ufffd"], [2]], [["\ufffd"], [2]], [["\ufffd", "\ufffd"], [2, 2]], [["\ufffd", "\ufffd"], [2, 3]], [["\ufffd", "\ufffd", "\ufffd"], [2, 2, 2]], [["\ufffd", "\ufffd", "\ufffd", "\ufffd", "\ufffd", "\ufffd"], [2, 2, 2, 2, 2, 2]], [["\ufffd"], [2]], [["\ufffd", "\ufffd", "\ufffd"], [2, 2, 2]], [["\ufffd", "\ufffd", "\ufffd"], [2, 2, 2]]]}, "109": {"explanation": "Explanation: The neuron is looking for the word \"bases\"", "answers": ["Activating tokens: bases (10)", "Activating tokens: bases (10)", "Activating tokens: bases (10)", "Activating tokens: bases (10)", "Activating tokens: bases (10)", "Activating tokens: bases (10)", "Activating tokens: bases (8)", "Activating tokens: bases (10)", "Activating tokens: bases (10)", "Activating tokens: bases (10)"], "correct": [[[" bases"], [9]], [[" bases"], [10]], [[" bases"], [9]], [[" bases"], [10]], [[" bases"], [10]], [[" bases"], [9]], [[" bases"], [9]], [[" bases"], [10]], [[" bases"], [10]], [[" bases"], [9]]]}, "110": {"explanation": "Explanation: The neuron is looking for punctuation marks, specifically parentheses", "answers": ["Activating tokens: (  (10)", "Activating tokens: (  (10), )  (10)", "Activating tokens: ) (10)", "Activating tokens: (  (10)", "Activating tokens: (  (2)", "Activating tokens: (  (5), )  (4)", "Activating tokens: ( ) (10)", "Activating tokens: (  (2), )  (2)", "Activating tokens: (  (10)", "Activating tokens: (  (10), )  (10)"], "correct": [[[")-"], [1]], [["/("], [0]], [["-(", "-("], [8, 8]], [[")-"], [2]], [["-("], [7]], [["-(", ")-"], [8, 1]], [[")-"], [1]], [[")-"], [1]], [[")-"], [1]], [["-(", "-("], [7, 8]]]}, "112": {"explanation": "Explanation: The neuron is looking for proper nouns or names, specifically those that are abbreviated (e", "answers": ["Activating tokens: Air Liquide (8), Enza NZ (8)", "Activating tokens: Jade (2)", "Activating tokens:  Ed (6)", "Activating tokens: HABS (8), KY (6)", "No activating tokens", "Activating tokens: Luke (5), Daryl (5), Lankester (5), Kayden (5), Michael (5)", "No activating tokens", "Activating tokens: D (1), F (1)", "Activating tokens: PELOSI (8), DEMOCRATS (6), BENGHAZI (8), TREY GOWDY (8), DARRELL ISSA (8), NANCY PELOSI (10), D", "Activating tokens: Dr"], "correct": [[[" Vern"], [9]], [[" mand"], [7]], [[" mand"], [7]], [[" Vern"], [9]], [[" Vern"], [9]], [[" Daryl"], [7]], [[" mand"], [7]], [[" Daryl"], [7]], [[" DEM"], [9]], [[" mand"], [7]]]}, "113": {"explanation": "Explanation: The neuron is looking for proper nouns that are names of people", "answers": ["Activating tokens: Merlin (3), Robert (1)", "Activating tokens: Harry Potter (8)", "Activating tokens: Robert Treskillard (8), Merlin (6), Arthur (6)", "Activating tokens: Dan Parent (3), Jim Amash (1), Glenn Whitmore (1), Jack Morelli (1)", "Activating tokens: Harry Potter (8), Dumbles (6)", "Activating tokens: Glenn Dromgoole (8)", "Activating tokens: Harry P", "Activating tokens: Wendy Williams (8), Rachel Ray (8), Nell Merlino (8)", "Activating tokens: Ari (8)", "Activating tokens: Harry, Voldemort (both 10)"], "correct": [[[" Merlin", " Merlin", " Merlin"], [13, 13, 13]], [["Harry"], [3]], [[" Merlin", " Merlin"], [13, 13]], [[" Glenn"], [3]], [["Harry"], [3]], [[" Glenn"], [3]], [["Harry"], [3]], [[" Merlin"], [13]], [[" Merlin"], [13]], [["Harry"], [3]]]}, "114": {"explanation": "Explanation: The neuron is looking for words related to rules, laws, or control, specifically \"governed\" and \"axis\"", "answers": ["Activating tokens: governed (8)", "Activating tokens: governed (8)", "Activating tokens: governed (8)", "Activating tokens: governed (8)", "Activating tokens: governed (10)", "Activating tokens: axis (8)", "Activating tokens: governed (8), law (4)", "Activating tokens: governed (8)", "Activating tokens: governed (10), law (6), laws (6)", "Activating tokens: governed (8)"], "correct": [[[" governed"], [12]], [[" governed"], [12]], [[" governed"], [12]], [[" governed"], [11]], [[" governed"], [12]], [[" axis"], [8]], [[" governed"], [12]], [[" governed"], [12]], [[" governed"], [11]], [[" governed"], [12]]]}, "115": {"explanation": "Explanation: The neuron is looking for the abbreviation \"ITE\", which likely stands for a specific term or phrase, possibly \"In-The-Ear\" in the context of hearing aids", "answers": ["No activating tokens", "No activating tokens", "No activating tokens", "No activating tokens", "No activating tokens", "Activating tokens: ITE (10)", "Activating tokens: ITE (10)", "Activating tokens: EXCITE (10)", "No activating tokens", "Activating tokens: ITE (10)"], "correct": [[["ITE"], [4]], [["ITE"], [1]], [["ITE"], [2]], [["ITE"], [3]], [["ITE"], [1]], [["ITE"], [1]], [["ITE"], [2]], [["ITE"], [2]], [["ITE", "ITE"], [2, 2]], [["ITE"], [1]]]}, "116": {"explanation": "Explanation: The neuron is looking for words related to fat or fatty substances in a nutritional context", "answers": ["Activating tokens: fats (8)", "Activating tokens: fats (8)", "No activating tokens", "No activating tokens", "No activating tokens", "Activating tokens: fatality (2)", "No activating tokens", "Activating tokens: fats (8), Polyunsaturated fats (9)", "Activating tokens: fat (4), fatigue (5)", "Activating tokens: fats (8)"], "correct": [[[" fats"], [7]], [[" fats"], [7]], [["fat"], [5]], [["fat"], [3]], [["fat"], [4]], [["fat"], [3]], [["alo"], [3]], [[" fats", " fats"], [7, 7]], [["fat"], [3]], [[" fats"], [7]]]}, "118": {"explanation": "Explanation: The neuron is looking for proper nouns, specifically names (Kathy, Kendra) or words that resemble them (Kend), as well as the word \"retaliation\" and its variants", "answers": ["Activating tokens: Ayla (8), Kendawg (9)", "Activating tokens: Kend (0), retaliation (10)", "Activating tokens: retaliation (8)", "Activating tokens: none (no names like Kathy, Kendra, or Kend; but \"retaliation\" is present with an activation value of 10)", "Activating tokens: Levine (8), retaliate (9)", "Activating tokens: Kendra (8)", "Activating tokens: Melissa (8), Susan (8), Ghida (8), Kathy (10)", "Activating tokens: Kendas (8)", "No activating tokens", "Activating tokens: Kathy (10)"], "correct": [[[" Kend"], [5]], [[" retaliation"], [4]], [[" retaliation"], [4]], [[" retaliation"], [4]], [[" retaliate"], [8]], [[" Kend"], [5]], [[" Kathy"], [4]], [[" Kend"], [5]], [[" shorten"], [4]], [[" Kathy"], [4]]]}, "120": {"explanation": "Explanation: The neuron is looking for the word \"numerous\"", "answers": ["Activating tokens: numerous (10)", "Activating tokens: numerous (10)", "Activating tokens: numerous (8)", "Activating tokens: numerous (10)", "Activating tokens: numerous (10)", "Activating tokens: numerous (10)", "Activating tokens: numerous (10)", "Activating tokens: numerous (10)", "Activating tokens: numerous (10)", "Activating tokens: numerous (8)"], "correct": [[[" numerous"], [5]], [[" numerous"], [5]], [[" numerous"], [5]], [[" numerous"], [5]], [[" numerous"], [5]], [[" numerous"], [5]], [[" numerous"], [5]], [[" numerous"], [5]], [[" numerous"], [5]], [[" numerous"], [5]]]}, "121": {"explanation": "Explanation: The neuron is looking for the prefix \"ener\" in words such as \"energy\", \"energize\", or others", "answers": ["Activating tokens: energ- (in \"Sopraceneri\") (5)", "Activating tokens: reenergize (10)", "No activating tokens", "No activating tokens", "No activating tokens", "Activating tokens: Microenergetic (8), Micro-Engineered (8)", "Activating tokens: re-energize (8)", "No activating tokens", "No activating tokens", "Activating tokens: energy (8), energies (8)"], "correct": [[["ener"], [16]], [["ener"], [17]], [["ener"], [17]], [["ener"], [17]], [["ener"], [15]], [["ener"], [17]], [["ener"], [18]], [["ener"], [15]], [["ener"], [15]], [["ener"], [17]]]}, "122": {"explanation": "Explanation: The neuron is looking for words related to direction or movement, such as \"way\", \"on\", and prefixes/suffixes like \"-gal-\" that may indicate a sense of place or direction", "answers": ["Activating tokens: around (8), way (9), about (6), go (7)", "Activating tokens: aboard (5), Galapagos (5)", "Activating tokens: Galapagos (8), to (2)", "Activating tokens: on (2), outside (4)", "Activating tokens: way (8), out (6), on (4)", "Activating tokens: on (2), gal- (4)", "Activating tokens: to (2), gal- (1)", "Activating tokens: on (2)", "Activating tokens: from (4), runs (3), around (5), Gal- (8)", "Activating tokens: directed (8)"], "correct": [[["way", ",", "if"], [3, 1, 0]], [["agos", "agos", "agos", "o", "agos", "agos", "agos"], [2, 3, 3, 1, 3, 3, 3]], [["agos"], [3]], [["erie", ",", "ician"], [3, 1, 2]], [["vest", "on"], [4, 4]], [["way", " (", ":"], [3, 1, 0]], [["a"], [2]], [[" Gad"], [2]], [["way", "."], [3, 0]], [["a"], [3]]]}, "124": {"explanation": "Explanation: The neuron is looking for abbreviations or acronyms, specifically those in all capital letters (e", "answers": ["Activating tokens: BLK, GI, TQ (10)", "Activating tokens: AME (8), AS (6), INC (5)", "Activating tokens: JC (8), DW (8), FIVE (not an acronym, but a word in all capital letters)", "Activating tokens: WOMB (8)", "Activating tokens: THIRST-C (10), BUFF BONZ (10), SUPER-V (10), D-FENSE (10)", "Activating tokens: EPS (8), GROW (5)", "Activating tokens: FIG (5), STR9 (5)", "Activating tokens: KDL32EX700 (8), KDL46EX700 (8), STRDG (7)", "Activating tokens: STR7 (10)", "Activating tokens: EULA (8)"], "correct": [[["STR"], [3]], [["ENSE"], [2]], [[" SPACE"], [11]], [["STR"], [3]], [["ENSE"], [3]], [["STR"], [3]], [["STR"], [3]], [["STR"], [3]], [["STR"], [3]], [["ENSE"], [2]]]}, "126": {"explanation": "Explanation: The neuron is looking for the concept of data or information being easily usable or understandable by humans", "answers": ["Activating tokens: user-accessible (8)", "Activating tokens: accessible (8), anytime (6), anyhow (6)", "Activating tokens: human-readable (8)", "Activating tokens: accessible (8)", "Activating tokens: easy (8), accessible (7)", "No activating tokens", "Activating tokens: information (2)", "No activating tokens", "Activating tokens: accessible (10), accessible (10)", "Activating tokens: readable (8)"], "correct": [[["accessible"], [1]], [[" accessible"], [1]], [["readable"], [2]], [[" accessible"], [0]], [[" accessible"], [1]], [[" accessible"], [0]], [[" accessible"], [1]], [[" accessible"], [1]], [[" accessible", " accessible"], [0, 0]], [["readable"], [1]]]}, "127": {"explanation": "Explanation: The neuron is looking for the word \"paper\" in various contexts", "answers": ["Activating tokens: Paper (8)", "Activating tokens: Paperwork (8)", "Activating tokens: paper (10)", "No activating tokens", "Activating tokens: paper (8)", "Activating tokens: Paper (8)", "Activating tokens: paper (8)", "Activating tokens: flypaper (8)", "Activating tokens: Paper Towels (8), Freezer Paper (8)", "Activating tokens: paper (8)"], "correct": [[[" Paper"], [4]], [["Paper"], [5]], [["paper"], [8]], [["paper"], [5]], [["paper"], [8]], [[" Paper"], [5]], [[" Paper"], [4]], [["paper"], [7]], [[" Paper", " Paper"], [5, 4]], [["paper"], [7]]]}, "128": {"explanation": "Explanation: The neuron is looking for words related to a carousel or a rotating display", "answers": ["No activating tokens", "No activating tokens", "No activating tokens", "No activating tokens", "No activating tokens", "No activating tokens", "Activating tokens: carousel (8)", "No activating tokens", "Activating tokens: carousel (8)", "Activating tokens: revolving (8), lazy (6), rotating (8), carousel (10)"], "correct": [[[" embarked"], [7]], [["Emb", "Emb"], [6, 6]], [[" embarked"], [7]], [["Emb"], [6]], [["Emb"], [6]], [[" embarked"], [7]], [["ousel"], [7]], [["Emb"], [6]], [["ousel"], [7]], [["ousel"], [7]]]}, "129": {"explanation": "Explanation: The neuron is looking for references to people who run, either as athletes or in a general sense", "answers": ["Activating tokens: None", "No activating tokens", "Activating tokens: runners-up (8)", "No activating tokens", "Activating tokens: runners (8)", "Activating tokens: runners (8)", "Activating tokens: None", "Activating tokens: runners (8)", "Activating tokens: Bowman (8), runners (7), Tim Thornburg (8)", "Activating tokens: runner (8), runners (8)"], "correct": [[[" runners"], [8]], [[" runners"], [9]], [[" runners"], [9]], [[" runners"], [9]], [[" runners", " runners"], [9, 9]], [[" runners"], [9]], [[" runners"], [8]], [[" runners"], [9]], [[" runners"], [9]], [[" runner", " runners"], [5, 9]]]}, "132": {"explanation": "Explanation: The neuron is looking for the names \"Jennifer\" and \"prowl\"", "answers": ["Activating tokens: Jennifer (8)", "Activating tokens: prowling (8)", "Activating tokens: Jennifer (10)", "Activating tokens: Jennifer (8)", "Activating tokens: Jennifer (10)", "Activating tokens: Jennifer (8)", "Activating tokens: prowl (8)", "Activating tokens: Jennifer (2)", "Activating tokens: Jennifer (8)", "Activating tokens: Jennifer (8)"], "correct": [[[" Jennifer"], [5]], [[" prow"], [15]], [[" Jennifer"], [6]], [[" Jennifer"], [6]], [[" Jennifer"], [6]], [[" Jennifer"], [5]], [[" prow"], [15]], [[" Jennifer", " Jennifer"], [5, 5]], [[" Jennifer"], [6]], [[" Jennifer"], [5]]]}, "133": {"explanation": "Explanation: The neuron is looking for mentions of sports leagues or competitions, such as Champions League, Europa League, Premier League, etc", "answers": ["Activating tokens: Champions League (8)", "No activating tokens", "Activating tokens: League (2)", "Activating tokens: Champions League (10)", "Activating tokens: Europa Conference League (8), League (5)", "Activating tokens: League Two (8)", "Activating tokens: Champions League (8)", "Activating tokens: Arab League (8)", "Activating tokens: Champions League (10)", "Activating tokens: Tunisian Ligue 1 (8), CAF Champions League (9)"], "correct": [[[" League"], [4]], [["League"], [4]], [[" league", " League"], [2, 4]], [[" League"], [4]], [[" League", "League"], [3, 4]], [["League"], [4]], [[" League"], [3]], [[" League"], [4]], [[" League"], [4]], [[" League"], [4]]]}, "134": {"explanation": "Explanation: The neuron is looking for words or phrases that indicate a middle point or intermediate stage, such as \"midway\", \"halfway\", or similar concepts", "answers": ["Activating tokens: midway (8)", "No activating tokens", "Activating tokens: midway (8)", "No activating tokens", "Activating tokens: midway (8), half (8)", "Activating tokens: midway (8)", "Activating tokens: halfway (8)", "Activating tokens: halfway (8)", "Activating tokens: midway (8)", "Activating tokens: midway (8)"], "correct": [[[" midway"], [2]], [["\u306a"], [2]], [[" midway"], [2]], [["\u305f"], [2]], [[" midway"], [2]], [[" midway"], [2]], [[" halfway"], [1]], [[" halfway"], [1]], [[" midway"], [2]], [[" midway"], [2]]]}}